<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Private Adaptations of Open LLMs Outperform their Closed Alternatives</title>
    <meta name="description"
          content="by Adam Dziedzic and Franziska Boenisch">
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/group.css">
    <link rel="canonical" href="/2024/12/10/open-llms.html">
    <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico">

    

</head>


<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="/">
                <img
                        src="/assets/logos/adams-logo-twitter-long-small-no-background-small2.svg" height="50"
                        class="imgnavbar"
                        alt="" style="padding-right: 0pt; padding-left: -20pt; margin-top: -12px;">
            </a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="/">Home</a></li>
                <li><a href="/team">Team</a></li>
                <li><a href="/positions">Open Positions</a></li>
<!--                <li><a href="/publications">Publications</a></li>-->
                <li><a href="/blog">Blog</a></li>
                <li><a href="/phdlife">PhDLife</a></li>
            </ul>
        </div>
    </div>
</div>



<div class="container-fluid" style="position: relative;min-height: 100vh;">
    <div id="content-wrap" style="padding-bottom: 5.5rem;">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Private Adaptations of Open LLMs Outperform their Closed Alternatives</h1>
    <p class="post-meta"><time datetime="2024-12-10T00:00:00-08:00" itemprop="datePublished">Dec 10, 2024</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p><em>by Adam Dziedzic and Franziska Boenisch</em></p>

<p>Nowadays, Large Language Models (LLMs) perform a plethora of language tasks. OpenAI exposes its GPT4 model to perform tasks such as text generation, translation, dialog summarization, code generation, and many others. While the <em>closed LLMs</em>, like GPT4, are exposed via public APIs or web interfaces, the <em>open LLMs</em>, like Llama, are released directly their parameters and allow us to simply download their parameters and and run the model locally. While LLMs have strong zero-shot performance, they still require <em>adaptations</em>, such as prompting or fine-tuning to perform well on specialized downstream tasks. Given that downstream tasks often rely on sensitive data, we need to ensure this data’s privacy when adapting LLMs.</p>

<p>In this blog post which is based on our latest <a href="https://openreview.net/forum?id=Jf40H5pRW0">NeurIPS 2024 paper</a>, <strong>we compare private adaptations for open vs. closed LLMs on multiple axes and find that by adapting open LLMs instead of closed ones, we can preserve more privacy and obtain higher performance at lower cost.</strong> On the way, we also design novel private prompting methods for generative tasks. Let’s explore how we do that.</p>

<h3 id="open-llms-have-comparable-performance-to-closed-llms">Open LLMs have comparable performance to Closed LLMs</h3>

<p>The closed LLMs such as GPT from OpenAI can be used via APIs whereas the open-weight models like Llama release the model parameters. The most preferable open-source LLMs like Pythia and OLMo provide us also with the data used for their training and the corresponding source code. The open LLMs have to be run on-premise or in the cloud. The most recent results from the standard benchmarks (such as MMLU that measures knowledge acquired by LLMs during pretraining) show that <strong>open-weight LLMs such as Llama 3.1 405 B closed the gap in performance with closed-source LLMs for the first time</strong>.</p>

<h3 id="llm-adaptations-on-open-llms-outperform-their-closed-alternatives">LLM Adaptations on open LLMs outperform their closed alternatives</h3>

<p>Pre-trained LLMs perform well on the general understanding tasks, however, they do not perform well enough on specialized downstream tasks. For example, for the DBpedia task, to classify Wikipedia articles, we observe that after adapting the LLM to the task, we can boost the performance by more than 40%. Additionally, behind the scenes, the training of the LLMs from scratch is a costly venture. Thus, instead of training the LLM on our own or using only their pre-trained versions, we adapt the LLMs to specialized downstream tasks. The adaptation of LLMs can be done in a plethora of ways and here we will present three main ones.</p>

<div style="text-align:center; margin-bottom:30px;">
  <p><img src="/assets/blog/openLLMs/adaptations.png" width="50%" /></p>
</div>

<p>One of the most popular ways to adapt LLMs is through prompting (denoted as 1. Input Prompt in the above figure). The input prompts can be discrete where you prepend additional natural language text to your standard input. Soft prompts are a learnable set of parameters prepended to the input embeddings. Prefix tuning is similar to the soft prompt but apart from being prepended to the input, it can also be prepended to every attention layer.</p>

<p>The second approach to adapt LLMs is through inner fine-tuning (the 2nd adaptation in the figure). You can do it either through full fine-tuning, where you adjust all the parameters of your LLM, or using a low-rank adaptation, abbreviated as LoRA, where a small set of additional parameters are added to many layers inside an LLM. Finally, we can fine-tune a couple of the last layers or even add an additional layer or more layers on top of an LLM (the 3-rd type of adaptation in the above figure).</p>

<p>If you want to adapt a closed LLM such as GPT4, you can use only the discrete prompts or last-layer fine-tuning, so-called weak adaptations. These adaptations are less performant than the <em>strong</em> gradient-based methods, such as prefix tuning or LoRA. Contrary to closed LLMs, the open LLMs can be adapted with any of the adaptation methods. The gradient-based adaptations used with open LLMs outperform the other approaches like discrete prompts or last-layer fine-tuning performed on closed LLMs.</p>

<h3 id="more-privacy-is-leaked-through-adaptations-of-closed-vs-open-llms">More privacy is leaked through adaptations of closed vs open LLMs</h3>

<div style="text-align:center; margin-bottom:30px;">
  <p><img src="/assets/blog/openLLMs/setup.png" width="50%" /></p>
</div>

<p>We consider two scenarios of adapting open vs closed LLMs. Let us imagine that there is a company, a data curator, which hosts private data locally on-premise.</p>

<p><strong>Open LLMs.</strong> The data curator can adapt an open LLM on their private data so that it can cater to a specific downstream task. Then, a customer can query the adapted open LLM. Notice, that the customer sends the query directly to the party hosting the LLM and no third parties are involved in the process. However, the querying party might be malicious. In this case, the private information from the data curator can leak to the querying party through the returned answers of the prompted LLM.</p>

<p><strong>Closed LLMs.</strong> Let us also consider the case when the data curator does not have any open LLM on-premise and would like to use a closed LLM from a model provider, for example, GPT4 exposed by the API from OpenAI. First, the closed LLM must be adapted to the private data. For the closed LLMs, this can be done by discrete prompts. However, the private data is directly released to the LLM provider (case 1 in the figure above). Second, the private queries from a customer must be routed through the LLM provider. Thus, also the private queries from the customers leak to the LLM providers (case 2). Finally, again, the answers returned to the querying party can leak information contained in the private data hosted by the data curator (case 3).</p>

<p>Overall, the conceptual analysis shows that the privacy leakage is much higher when adapting closed LLMs vs open LLMs. So, for open LLMs only answers can leak some private information. On the other hand, the private data and queries leak to the provider of the closed LLM. Next, we will investigate how to prevent privacy leakage.</p>

<h3 id="private-llm-adaptations-for-text-generation">Private LLM Adaptations for text generation</h3>

<p>We identified that there is a lack of support for the text generation (e.g., the dialog summarization task) with the private prompts. If you want to learn more about how to provide privacy for text classification tasks with prompts, then check out our other blog post <a href="https://sprintml.com/2024/04/27/private-prompts.html">here</a>.</p>

<p>To eanble private text generation with discrete prompts, we start, as in PromptPATE, with our private labeled data. We divide the data into many subsets to form prompts. Each prompt contains a disjoint set of examples or shots from the private labeled data. The disjoint subsets from the private labeled data are used to create the demonstrations for private teacher prompts. The data serves as private shots. Then, we use unlabeled public data to query the LLM with the private teacher prompts. The resulting method is called PromptDPSGDGen.</p>

<p>We incorporate the DP-SGD algorithm into the training of gradient-based adaptations, such as soft prompt, prefix tuning, or LoRA. Here, we give an example with soft prompts. We start from our initial parameters for soft prompt embeddings. We also have our private data with labels. We provide a private example and embed it. The embeddings are prepended with our soft prompt embeddings. The embeddings with prepended soft prompt go as an input to the LLM. Based on the expected labels, we can compute the loss and provide gradients for our soft prompt embeddings. To make sure that the gradients do not leak information about our private data, we clip the gradients and add noise. Thus, this method for text generation, called PromptDPSGDGen obtains the input gradients from the LLM and performs DPSGD to update the soft prompt parameters while keeping the underlying LLM frozen.</p>

<h3 id="private-llm-adaptations-on-open-llms-outperform-their-closed-alternatives">Private LLM Adaptations on open LLMs outperform their closed alternatives</h3>

<p>We carried out an in-depth comparison of the adaptations of open vs closed LLMs considering privacy protection, performance, and cost. The <em>privacy protection</em> is assessed in terms of the leakage of private data either to the LLM provider or the querying party (a user of the adapted LLM), as well as the leakage of the users’ queries to the LLM provider. The <em>performance</em> is measured in terms of accuracy for classification tasks and the scores like Rouge or BLEU for the text generation tasks. Finally, the <em>cost</em> is the amount of money in dollars needed to adapt a given LLM with privacy.</p>

<p>Overall, we analyzed 4 recent methods to adapt closed LLMs including our PromptPATEGen. All of them were designed for closed LLMs to prevent the leakage of private data to the querying party. All of them fulfill this goal. However, they leak private data and queries to the LLM provider. The only method that does not leak private data to the LLM provider is <a href="https:
//openreview.net/forum?id=Ifz3IgsEPX">DP-OPT</a>. But DP-OPT requires the data curator to use an open LLM on-premise. Most importantly, if we privately adapt open LLMs only, then we only have to prevent the leakage of private data to the querying party. Note that any of the adaptation method can be used for open LLMs.</p>

<p>We find that the adaptations of open LLMs offer high privacy protection and high performance at low cost. On the other hand, the prompt-based adaptations for closed LLMs provide lower privacy protection and lower performance at a higher cost compared to their open counterparts. We further analyze the privacy-utility trade-off for classification and generation tasks across different privacy budgets. We show that even under tight privacy constraints (ε &lt; 1.0), the privacy-preserving adaptations for open LLMs perform significantly better than the ones for closed LLMs.</p>

<p>Let us analyze in detail the private adaptations for text generation tasks, such as dialog summarization. We present the result in the Table below. We use 10k queries and set the default privacy budget to 8. The metrics used are Rouge, where Rouge-1 it to assess how many unigrams in the generated text agree with the expected LLM output. Rouge-2 is similar but uses bi-grams. Rouge-L refers to the similarity of the longest common subsequence between prediction and target. The first analyzed adaptation was for closed LLMs, which is DP-ICL for discrete prompts. The cost of using DP-ICL method on GPT-4 Turbo skyrockets to 3419 dollars, while obtaining rather low performance. However, adapting Open Llama 13B using our PromptPATEGen outperforms DP-ICL at a much lower cost of less than 20 dollars. We can further lower the cost and decrease the model size using our PromptDPSGDGen. This adaptation outperforms other methods at a very low cost of only roughly 2 dollars. Then, we can boost performance if we apply private LoRA instead of PromptDPSGD on the same LLM. Finally, we can leverage one of the top-notch open LLMs, namely Mixtral 8x7B to obtain the highest performance, however, at a substantial increase in the cost to around 68 dollars.</p>

<table>
  <thead>
    <tr>
      <th>Adaptation</th>
      <th>LLM</th>
      <th>Rouge-1</th>
      <th>Rouge-2</th>
      <th>Rouge-L</th>
      <th>Cost ($)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DP-ICL</td>
      <td>GPT4-Turbo</td>
      <td>41.8</td>
      <td>17.3</td>
      <td>33.4</td>
      <td>3419</td>
    </tr>
    <tr>
      <td>PromptPATEGen</td>
      <td>Open Llama 13B</td>
      <td>43.4</td>
      <td>19.7</td>
      <td>34.2</td>
      <td>19.43</td>
    </tr>
    <tr>
      <td>PromptDPSGDGen</td>
      <td>BART Large</td>
      <td>46.1</td>
      <td>21.3</td>
      <td>37.4</td>
      <td>2.13</td>
    </tr>
    <tr>
      <td>Private LoRA</td>
      <td>BART Large</td>
      <td>48.8</td>
      <td>23.5</td>
      <td>39.1</td>
      <td>3.59</td>
    </tr>
    <tr>
      <td>Private LoRA</td>
      <td>Mixtral 8x7B</td>
      <td>52.8</td>
      <td>29.6</td>
      <td>44.7</td>
      <td>67.95</td>
    </tr>
  </tbody>
</table>

<h3 id="conclusions">Conclusions</h3>

<p>In the blog post, we presented our novel private prompting methods that support text generation tasks. We also evaluated private adaptations for open and closed LLMs. Our key takeaways are that the adaptations of open LLMs are:</p>

<ol>
  <li>more private than closed LLM adaptations since they have significantly fewer possibilities for privacy leakage;</li>
  <li>more performant than closed LLM adaptations: at the same privacy level, even using much smaller models, we can obtain higher performance with open LLMs due to their ability to support gradient-based adaptation methods;</li>
  <li>more cost-effective than closed LLM adaptations that incur continuous query costs to an LLM provider.</li>
</ol>

<p>If you’d like to learn more, read our NeurIPS 2024 paper <a href="https://adam-dziedzic.com/static/assets/papers/openLLMs.pdf">“Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives”</a>. It goes into greater detail about our research on this topic.</p>

  </div>

</article>

    </div>
</div>

<div id="footer">
    <div class="panel-footer">
        <div class="container-fluid">
            <div class="row">
                <p>&copy 2024 SprintML Lab</p>
            </div>
        </div>
    </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="/js/bootstrap.min.js"></script>


</body>

</html>
